# Associations with DN Regulation

Note that actual code is loaded from a different file.

```{r external-code, cache=FALSE}
read_chunk('05_dn_regulation.R')
```

## Overview

There were several interesting results that emerged from these analyses:

* Scores on the RRS Brooding sub-scale are highly and significantly related to DN regulation.
* Connectivity between the DMN and TP networks are marginally related to real-time prediction accuracy.
* The number of change points in an individual's DMN time-series is significantly related to real-time prediction accuracy. More on change points below.

## Setup

```{r general-setup, message=FALSE, results='hide'}
```

```{r network-setup}
```

```{r phenotypes}
```

## Brain Measures

### Network Connectivity

```{r connectivity}
```

This is the group average connectivity with the DMN.

### Kurtosis

```{r kurtosis}
```

### Autocorrelation

As another measure of stability of the DMN time-series, I looked at it's autocorrelation. I wasn't totally sure how to summarize it, so I calculated the number of lags it took for an individuals DMN time-series to have a correlation of zero.

```{r autocorrelation}
```

### Change Points

As another measure of the stability of the DMN time-series and to capture changes in brain state that might occur during rest, I used bayesian change point analysis. Essentially, it looks in a time-series for points in time when there is a significant change signal. Another motivation for using this was based on the finding that real-time prediction accuracy was significantly related to an individual's RRS Brooding subscale. I made the reverse inference that since 'brooding' engages the DMN, one might expect that at rest those individuals with higher RRS Brooding scores to have less state changes in the DMN. There are probably a dozen ways to summarize the results from the change point analysis, I determined a change point to be a time with a posterior probability greater than 0.5 and simply calculated the number of such 'change points' in each individual's time-series. Incidently, though the change point summary measure I use is significantly related to prediction accuracy, it isn't significantly related to RRS Brooding (but it's close p=0.2). 

```{r changepoints, fig.width=8, fig.height=4}
```

### Prediction

```{r prediction}
```

Quick plot showing that the with feedback condition seems to have slightly greater real-time prediction accuracy than the no feedback condition. For all later analyses, I will ignore the feedback condition.

```{r prediction-difference}
```

```{r combine}
```

## Prediction Accuracy Associations

### with Brain Measures

#### Kurtosis

Nope not significant.

```{r kurtosis-prediction}
```

#### Autocorrelation

Significant. Again here I took the number of lags until the autocorrelation of the DMN time-series was 0 or below 0. Thus, someone who is good at regulating their DMN activity also is less likely to see slower changes in their DMN time-series (or at least I think that's what it means).

```{r lag-prediction}
```

#### Change Points

Strange that this is no longer significant since the plot looks pretty good. As before, it probably isn't helpful that a bunch of individuals have the same number of change points. Again here I calculated the number of points in the DMN time-series that a significant change in the signal occured.

```{r nchanges-prediction}
```

### TP Connectivity

DMN connectivity with the left fronto-parietal is significant with the others coming close (there does appear to be an outlier with the right frontoporietal network).

```{r connectivity-prediction}
```

### MDMR

Had to throw this in. The first analysis is significant, so the pattern of connectivity between the DMN and the other networks significantly predicts real-time prediction accuracy.

```{r cwas-prediction}
```

### with Phenotypic Measures

```{r functions-prediction}
```

#### Total Scale Scores (with BDI, without PANAS)

##### Multiple Regression

Here, only RRS is significant and there are no outliers.

```{r multiple-totals-prediction, fig.width=12, fig.height=4}
```

##### Single Regressions

Here, SIPI and RRS are both significant and subject 1 is an outlier in the AIM and SIPI analyses.

```{r single-totals-prediction, fig.width=12, fig.height=4}
```

#### Total Scale Scores (with PANAS, without BDI)

##### Multiple Regression

RRS is significant and ERQ is marginally significant.

**BELOW IS RELEVANT FOR A MODEL WITHOUT PANAS**
Not sure why BDI had such a huge effect since now every measure except ERQ is significant. However, oddly subjects 3 and 5 are outliers even though they seem to fit the data fairly well. Note there is a disconnect with the way I run the regression to get significance and the way I get build the best fit lines...I can explain this more in person or on the phone.
**ABOVE IS RELEVANT FOR A MODEL WITHOUT PANAS**

```{r multiple-totals-prediction-no-bdi, fig.width=12, fig.height=4}
```

##### Single Regressions

Of course there is no point in re-running this here.

#### RRS SubScales

##### Multiple Regression

Only the RRS Brooding is significant here. I am not sure why subject 5 is chosen as an outlier here. 

```{r multiple-rrs-prediction, fig.width=10, fig.height=4}
```

##### Single Regressions

I am not sure why it crashes with RRS_Reflection. It doesn't converge in the RRS Reflection case but from what I can tell there is nothing weird about this data.

```{r single-rrs-prediction, fig.width=10, fig.height=4}
```

#### SIPI SubScales

##### Multiple Regression

The Guilt and Fear of Failure of Day Dreaming questionnaire is marginally significant.

```{r multiple-sipi-prediction, fig.width=8, fig.height=4}
```

##### Single Regressions

None of them are significant!

```{r single-sipi-prediction, fig.width=8, fig.height=4}
```

#### ERQ SubScales

##### Multiple Regression

Nothing.

```{r multiple-erq-prediction, fig.width=8, fig.height=4}
```

##### Single Regressions

The Reappraisal subscale was significant and it choose subject 2 as an outlier.

```{r single-erq-prediction, fig.width=8, fig.height=4}
```

#### PANAS SubScales

##### Multiple Regression

Nothing.

```{r multiple-panas-prediction, fig.width=8, fig.height=4}
```

##### Single Regression

Nothing.

```{r single-panas-prediction, fig.width=8, fig.height=4}
```

### with Phenotypic Measures but NO Age and Sex

```{r functions-prediction}
```

#### Total Scale Scores (with BDI, without PANAS)

##### Multiple Regression

```{r multiple-totals-prediction-just-say-no, fig.width=12, fig.height=4}
```

##### Single Regressions

```{r single-totals-prediction-just-say-no, fig.width=12, fig.height=4}
```

#### Total Scale Scores (with PANAS, without BDI)

##### Multiple Regression

```{r multiple-totals-prediction-no-bdi-just-say-no, fig.width=12, fig.height=4}
```

##### Single Regressions

Of course there is no point in re-running this here.

#### RRS SubScales

##### Multiple Regression

```{r multiple-rrs-prediction-just-say-no, fig.width=10, fig.height=4}
```

##### Single Regressions

```{r single-rrs-prediction-just-say-no, fig.width=10, fig.height=4}
```

#### SIPI SubScales

##### Multiple Regression

```{r multiple-sipi-prediction-just-say-no, fig.width=8, fig.height=4}
```

##### Single Regressions

```{r single-sipi-prediction-just-say-no, fig.width=8, fig.height=4}
```

#### ERQ SubScales

##### Multiple Regression

```{r multiple-erq-prediction-just-say-no, fig.width=8, fig.height=4}
```

##### Single Regressions

```{r single-erq-prediction-just-say-no, fig.width=8, fig.height=4}
```

#### PANAS SubScales

##### Multiple Regression

```{r multiple-panas-prediction-just-say-no, fig.width=8, fig.height=4}
```

##### Single Regression

```{r single-panas-prediction-just-say-no, fig.width=8, fig.height=4}
```


### with Phenotypic Measures but NO Age and Sex and NO Subject 1 (CCD014)

#### Total Scale Scores (with BDI, without PANAS)

##### Multiple Regression

```{r multiple-totals-prediction-just-say-no-no1, fig.width=12, fig.height=4}
```

##### Single Regressions

```{r single-totals-prediction-just-say-no-no1, fig.width=12, fig.height=4}
```

#### Total Scale Scores (with PANAS, without BDI)

##### Multiple Regression

```{r multiple-totals-prediction-no-bdi-just-say-no-no1, fig.width=12, fig.height=4}
```

##### Single Regressions

Of course there is no point in re-running this here.

#### RRS SubScales

##### Multiple Regression

```{r multiple-rrs-prediction-just-say-no-no1, fig.width=10, fig.height=4}
```

##### Single Regressions

```{r single-rrs-prediction-just-say-no-no1, fig.width=10, fig.height=4}
```

#### SIPI SubScales

##### Multiple Regression

```{r multiple-sipi-prediction-just-say-no-no1, fig.width=8, fig.height=4}
```

##### Single Regressions

```{r single-sipi-prediction-just-say-no-no1, fig.width=8, fig.height=4}
```

#### ERQ SubScales

##### Multiple Regression

```{r multiple-erq-prediction-just-say-no-no1, fig.width=8, fig.height=4}
```

##### Single Regressions

```{r single-erq-prediction-just-say-no-no1, fig.width=8, fig.height=4}
```

#### PANAS SubScales

##### Multiple Regression

```{r multiple-panas-prediction-just-say-no-no1, fig.width=8, fig.height=4}
```

##### Single Regression

```{r single-panas-prediction-just-say-no-no1, fig.width=8, fig.height=4}
```

